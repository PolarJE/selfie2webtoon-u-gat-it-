{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selfie to webtoon U-GAT-IT (Tensorflow 2.0.0 -rc0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras import layers, models, Model\n",
    "if tf.__version__ != '2.0.0-rc0':\n",
    "    raise Exception('Tensorflow Version is not correct, Required Version : 2.0.0-rc0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_he = tf.initializers.he_normal(2019)\n",
    "init_rand_norm = tf.random_normal_initializer(0., 0.02)\n",
    "kernel_regularizer = tf.keras.regularizers.l2(0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instance_norm(x):\n",
    "    eps = 1e-5\n",
    "    ins_mean, ins_sigma = tf.nn.moments(x, axes=[1, 2])\n",
    "    return (x - ins_mean) / (tf.sqrt(ins_sigma + eps))\n",
    "\n",
    "def layer_norm(x):\n",
    "    eps = 1e-5\n",
    "    ln_mean, ln_sigma = tf.nn.moments(x, axes=[1, 2, 3])\n",
    "    return (x - ln_mean) / (tf.sqrt(ln_sigma + eps))\n",
    "\n",
    "def layer_instance_norm(x):\n",
    "    ch = np.shape(x)[-1]\n",
    "    x_ins = instance_norm(x)\n",
    "    x_ln = layer_norm(x)\n",
    "    rho = tf.Variable(initial_value = np.zeros(ch),constraint=lambda x: tf.clip_by_value(x, clip_value_min=0.0, clip_value_max=1.0), dtype = tf.float32)\n",
    "    gamma = tf.Variable(initial_value = np.ones([ch]), dtype = tf.float32)\n",
    "    beta = tf.Variable(initial_value = np.zeros([ch]), dtype = tf.float32)\n",
    "\n",
    "    x_hat = rho * x_ins + (1 - rho) * x_ln\n",
    "    x_hat = x_hat * gamma + beta\n",
    "    return x_hat\n",
    "\n",
    "def adaptive_instance_layer_norm(x, gamma, beta, smoothing = True):\n",
    "    ch = np.shape(x)[-1]\n",
    "    x_ins = instance_norm(x)\n",
    "    x_ln = layer_norm(x)\n",
    "    if smoothing:\n",
    "        rho = tf.Variable(initial_value = np.ones([ch]) * 0.9,constraint=lambda x: tf.clip_by_value(x, clip_value_min=0.0, clip_value_max=0.9), dtype = tf.float32)\n",
    "    else:\n",
    "        rho = tf.Variable(initial_value = np.ones([ch]) * 1.0,constraint=lambda x: tf.clip_by_value(x, clip_value_min=0.0, clip_value_max=1.0), dtype = tf.float32)\n",
    "    x_hat = rho * x_ins + (1 - rho) * x_ln\n",
    "    x_hat = x_hat * gamma + beta\n",
    "    return x_hat\n",
    "\n",
    "def resblock(x_init, channels):\n",
    "    x = layers.Conv2D(channels, 3, strides = 1, padding = 'same')(x_init)\n",
    "    x = instance_norm(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(channels, 3, strides = 1, padding = 'same')(x)\n",
    "    x = instance_norm(x)\n",
    "    return x + x_init\n",
    "\n",
    "def adaptive_ins_layer_resblock(x_init, ch, gamma, beta) :\n",
    "    x = layers.Conv2D(ch, 3, strides = 1, padding = 'same')(x_init)\n",
    "    x = adaptive_instance_layer_norm(x, gamma, beta)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(ch, 3, strides = 1, padding = 'same')(x)\n",
    "    x = adaptive_instance_layer_norm(x, gamma, beta)\n",
    "    return x + x_init\n",
    "\n",
    "def MLP(x, ch):\n",
    "    ch = np.shape(x)[-1]\n",
    "    x = global_avg_pooling(x)\n",
    "    for i in range(2) :\n",
    "        x, _ = fully_connected_with_w(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "    gamma= fully_connected(x, ch)\n",
    "    gamma = tf.reshape(gamma, shape = [-1, 1, 1, ch])\n",
    "    beta = fully_connected(x, ch)\n",
    "    beta = tf.reshape(gamma, shape = [-1, 1, 1, ch])\n",
    "    return gamma, beta\n",
    "\n",
    "def downsample(filters, size, input_shape = None):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False))\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "    return result\n",
    "def upsample(filters, size):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2,padding='same',kernel_initializer=initializer,use_bias=False))\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "    return result\n",
    "\n",
    "def global_avg_pooling(x):\n",
    "    gap = tf.reduce_mean(x, axis=[1, 2])\n",
    "    return gap\n",
    "\n",
    "def global_max_pooling(x):\n",
    "    gmp = tf.reduce_max(x, axis=[1, 2])\n",
    "    return gmp\n",
    "\n",
    "def flatten(x) :\n",
    "    return layers.Flatten()(x)\n",
    "\n",
    "def fully_connected_with_w(x):\n",
    "    x = flatten(x)\n",
    "    shape = x.get_shape().as_list()\n",
    "    channels = shape[-1]\n",
    "    w = tf.Variable(tf.random.normal([channels, 1], mean=0.0, stddev=0.02), tf.float32,)\n",
    "    x = tf.matmul(x, spectral_norm(w))\n",
    "    weights = tf.gather(tf.transpose(w), 0)\n",
    "    return x, weights\n",
    "def fully_connected(x, units):\n",
    "    x = flatten(x)\n",
    "    shape = x.get_shape().as_list()\n",
    "    channels = shape[-1]\n",
    "    w = tf.Variable(tf.random.normal([channels, units], mean=0.0, stddev=0.02), tf.float32,)\n",
    "    \n",
    "    x = tf.matmul(x, spectral_norm(w))\n",
    "    return x\n",
    "\n",
    "def spectral_norm(w, iteration=1):\n",
    "    w_shape = w.shape.as_list()\n",
    "    w = tf.reshape(w, [-1, w_shape[-1]])\n",
    "    u = tf.Variable(tf.random.normal([1, w_shape[-1]]))###########\n",
    "\n",
    "    u_hat = u\n",
    "    v_hat = None\n",
    "    for i in range(iteration):\n",
    "        v_ = tf.matmul(u_hat, tf.transpose(w))\n",
    "        v_hat = tf.nn.l2_normalize(v_)\n",
    "\n",
    "        u_ = tf.matmul(v_hat, w)\n",
    "        u_hat = tf.nn.l2_normalize(u_)\n",
    "\n",
    "    u_hat = tf.stop_gradient(u_hat)\n",
    "    v_hat = tf.stop_gradient(v_hat)\n",
    "\n",
    "    sigma = tf.matmul(tf.matmul(v_hat, w), tf.transpose(u_hat))\n",
    "\n",
    "\n",
    "    w_norm = w / sigma\n",
    "    w_norm = tf.reshape(w_norm, w_shape)\n",
    "\n",
    "\n",
    "    return w_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator():\n",
    "    ch = 256\n",
    "    down_stack = [\n",
    "        downsample(ch // 2, 3), \n",
    "        downsample(ch, 3)\n",
    "    ]\n",
    "\n",
    "    up_stack = [\n",
    "        upsample(ch, 3),\n",
    "        upsample(ch // 2, 3)\n",
    "    ]\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    inputs = tf.keras.layers.Input(shape=[256,256,3])\n",
    "    x = inputs\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "    for i in range(4):\n",
    "        x = resblock(x, ch)\n",
    "    \n",
    "    gap_att = global_avg_pooling(x)\n",
    "    cam_gap_logit, cam_x_weight = fully_connected_with_w(gap_att)\n",
    "    x_gap = tf.multiply(x, cam_x_weight)\n",
    "    \n",
    "    gmp_att = global_max_pooling(x)\n",
    "    cam_gmp_logit, cam_x_weight = fully_connected_with_w(gmp_att)\n",
    "    x_gmp = tf.multiply(x, cam_x_weight)\n",
    "    \n",
    "    cam_logit = tf.concat([cam_gap_logit, cam_gmp_logit], axis=-1)\n",
    "    x = tf.concat([x_gap, x_gmp], axis=-1)\n",
    "    \n",
    "    gamma, beta = MLP(x, ch)\n",
    "    \n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(ch * 2, 1, strides=1, padding='same', use_bias=False, activation = 'relu')(x)\n",
    "    \n",
    "    for i in range(4):\n",
    "        x = adaptive_ins_layer_resblock(x, ch * 2, gamma, beta)\n",
    "        \n",
    "    for up in up_stack:\n",
    "        x = up(x)\n",
    "        \n",
    "    last = layers.Conv2D(3, 1, strides = 1, padding = 'same', activation = 'tanh')(x)\n",
    "    return Model(inputs, [last, cam_logit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_downsample(filters, size, input_shape = None):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False))\n",
    "    result.add(tf.keras.layers.tf.keras.layers.LeakyReLU())\n",
    "    return result\n",
    "def discriminator_global(x, ch):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    down_stack = [\n",
    "        downsample(ch // 8, 3),\n",
    "        downsample(ch // 4, 3),\n",
    "        downsample(ch // 2, 3),\n",
    "        downsample(ch, 3)\n",
    "    ]\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        \n",
    "    gap_att = global_avg_pooling(x)\n",
    "    cam_gap_logit, cam_x_weight = fully_connected_with_w(gap_att)\n",
    "    x_gap = tf.multiply(x, cam_x_weight)\n",
    "    \n",
    "    gmp_att = global_max_pooling(x)\n",
    "    cam_gmp_logit, cam_x_weight = fully_connected_with_w(gmp_att)\n",
    "    x_gmp = tf.multiply(x, cam_x_weight)\n",
    "    \n",
    "    cam_logit = tf.concat([cam_gap_logit, cam_gmp_logit], axis=-1)\n",
    "    x = tf.concat([x_gap, x_gmp], axis=-1)\n",
    "    x = tf.keras.layers.Conv2D(ch, 1, strides=1, padding='same', kernel_initializer=initializer, use_bias=False)(x)\n",
    "    x = tf.keras.layers.Conv2D(1, 1, strides=1, padding='same', kernel_initializer=initializer, use_bias=False)(x)\n",
    "    return x, cam_logit\n",
    "\n",
    "def discriminator_local(x, ch):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    down_stack = [\n",
    "        downsample(ch // 2, 3),\n",
    "        downsample(ch, 3)\n",
    "    ]\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        \n",
    "    gap_att = global_avg_pooling(x)\n",
    "    cam_gap_logit, cam_x_weight = fully_connected_with_w(gap_att)\n",
    "    x_gap = tf.multiply(x, cam_x_weight)\n",
    "    \n",
    "    gmp_att = global_max_pooling(x)\n",
    "    cam_gmp_logit, cam_x_weight = fully_connected_with_w(gmp_att)\n",
    "    x_gmp = tf.multiply(x, cam_x_weight)\n",
    "    \n",
    "    cam_logit = tf.concat([cam_gap_logit, cam_gmp_logit], axis=-1)\n",
    "    x = tf.concat([x_gap, x_gmp], axis=-1)\n",
    "    x = tf.keras.layers.Conv2D(ch, 1, strides=1, padding='same', kernel_initializer=initializer, use_bias=False)(x)\n",
    "    x = tf.keras.layers.Conv2D(1, 1, strides=1, padding='same', kernel_initializer=initializer, use_bias=False)(x)\n",
    "    return x, cam_logit\n",
    "\n",
    "def Discriminator():\n",
    "        D_logit = []\n",
    "        D_CAM_logit = []\n",
    "        ch = 256\n",
    "        inputs = tf.keras.layers.Input(shape=[256,256,3])\n",
    "        local_x, local_cam= discriminator_local(inputs, ch)\n",
    "        global_x, global_cam = discriminator_global(inputs, ch)\n",
    "        D_logit.extend([local_x, global_x])\n",
    "        D_CAM_logit.extend([local_cam, global_cam])\n",
    "        return Model(inputs, [D_logit, D_CAM_logit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_list = glob.glob('./model_save/*')\n",
    "if len(saved_model_list) == 4:\n",
    "    print('load model')\n",
    "    gen_g = models.load_model('./model_save/gen_g.h5')\n",
    "    gen_f = models.load_model('./model_save/gen_f.h5')\n",
    "    dis_x = models.load_model('./model_save/dis_x.h5')\n",
    "    dis_y = models.load_model('./model_save/dis_y.h5')\n",
    "else:\n",
    "    print('make new model')\n",
    "    gen_g = Generator()\n",
    "    gen_f = Generator()\n",
    "    dis_x = Discriminator()\n",
    "    dis_y = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2\n",
    "lr = 2e-4\n",
    "lr = 0.0001\n",
    "gen_g_optimizer = tf.keras.optimizers.Adam(lr, beta_1=0.5)\n",
    "gen_f_optimizer = tf.keras.optimizers.Adam(lr, beta_1=0.5)\n",
    "dis_x_optimizer = tf.keras.optimizers.Adam(lr, beta_1=0.5)\n",
    "dis_y_optimizer = tf.keras.optimizers.Adam(lr, beta_1=0.5)\n",
    "\n",
    "loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LAMBDA = 10\n",
    "def discriminator_loss(real, generated):\n",
    "    real_loss = loss_obj(tf.ones_like(real), real)\n",
    "    generated_loss = loss_obj(tf.zeros_like(generated), generated)\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "    return total_disc_loss * 0.5\n",
    "\n",
    "def generator_loss(generated):\n",
    "    return loss_obj(tf.ones_like(generated), generated)\n",
    "\n",
    "def calc_cycle_loss(real_image, cycled_image):\n",
    "    loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "    return LAMBDA * loss1\n",
    "\n",
    "def identity_loss(real_image, same_image):\n",
    "    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "    return LAMBDA * 0.5 * loss\n",
    "\n",
    "def cam_loss(source, non_source) :\n",
    "\n",
    "    identity_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(source), logits=source))\n",
    "    non_identity_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(non_source), logits=non_source))\n",
    "    loss = identity_loss + non_identity_loss\n",
    "    return loss\n",
    "\n",
    "def L1_loss(x, y):\n",
    "    loss = tf.reduce_mean(tf.abs(x - y))\n",
    "    return loss\n",
    "\n",
    "def discriminate_real(x_A, x_B):\n",
    "    real_A_logit, real_A_cam_logit= dis_x(x_A)\n",
    "    real_B_logit, real_B_cam_logit= dis_y(x_B)\n",
    "    return real_A_logit, real_A_cam_logit, real_B_logit, real_B_cam_logit\n",
    "\n",
    "def discriminate_fake(x_ba, x_ab):\n",
    "    fake_A_logit, fake_A_cam_logit = dis_x(x_ba)\n",
    "    fake_B_logit, fake_B_cam_logit = dis_y(x_ab)\n",
    "    return fake_A_logit, fake_A_cam_logit, fake_B_logit, fake_B_cam_logit\n",
    "\n",
    "def generate_images(model, test_input, epoch):\n",
    "    prediction,_ = model(test_input)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "\n",
    "    display_list = [test_input[0], prediction[0]]\n",
    "    title = ['Input Image', 'Predicted Image']\n",
    "\n",
    "    for i in range(2):\n",
    "        plt.subplot(1, 2, i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i])\n",
    "        plt.axis('off')\n",
    "    plt.savefig('./save/image_at_epoch_{:04d}.jpg'.format(epoch))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_dir = './data/'\n",
    "img_folder = ['selfie', 'cartoon']\n",
    "X_array = np.load(basic_dir + 'selfie.npz')['arr_0']\n",
    "Y_array = np.load(basic_dir + 'cartoon.npz')['arr_0']\n",
    "Y_array = Y_array\n",
    "X_array = X_array\n",
    "print(X_array.shape, Y_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function # 데코레이터\n",
    "def train_step(real_x, real_y, gen_loss_weights):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        x_ab, cam_ab = gen_g(real_x)\n",
    "        x_ba, cam_ba = gen_f(real_y)\n",
    "\n",
    "        x_aba, _ = gen_f(x_ab)\n",
    "        x_bab, _ = gen_g(x_ba)\n",
    "\n",
    "        x_aa, cam_aa = gen_f(real_x)\n",
    "        x_bb, cam_bb = gen_g(real_y)\n",
    "        \n",
    "        real_A_logit, real_A_cam_logit, real_B_logit, real_B_cam_logit = discriminate_real(real_x, real_y)\n",
    "        fake_A_logit, fake_A_cam_logit, fake_B_logit, fake_B_cam_logit = discriminate_fake(x_ba, x_ab)\n",
    "    \n",
    "        cam_A = cam_loss(cam_ba, cam_aa)\n",
    "        cam_B = cam_loss(cam_ab, cam_bb)\n",
    "        \n",
    "        G_ad_loss_A = generator_loss(fake_A_logit[0]) + generator_loss(fake_A_logit[1])\n",
    "        G_ad_loss_B = generator_loss(fake_B_logit[0]) + generator_loss(fake_B_logit[1])\n",
    "\n",
    "        D_ad_loss_A = discriminator_loss(real_A_logit[0], fake_A_logit[0]) + discriminator_loss(real_A_logit[1], fake_A_logit[1])\n",
    "        D_ad_loss_B = discriminator_loss(real_B_logit[0], fake_B_logit[0]) + discriminator_loss(real_B_logit[1], fake_B_logit[1])\n",
    "        \n",
    "        D_cam_loss_A = discriminator_loss(real_A_cam_logit[0], fake_A_cam_logit[0]) + discriminator_loss(real_A_cam_logit[1], fake_A_cam_logit[1])\n",
    "        D_cam_loss_B = discriminator_loss(real_B_cam_logit[0], fake_B_cam_logit[0]) + discriminator_loss(real_B_cam_logit[1], fake_B_cam_logit[1])\n",
    "\n",
    "        identity_A = L1_loss(x_aa, real_x)\n",
    "        identity_B = L1_loss(x_bb, real_y)\n",
    "        \n",
    "        reconstruction_A = L1_loss(x_aba, real_x)\n",
    "        reconstruction_B = L1_loss(x_bab, real_y)\n",
    "        \n",
    "        Generator_A_gan = gen_loss_weights[0] * G_ad_loss_A\n",
    "        Generator_A_cycle = gen_loss_weights[1] * reconstruction_B\n",
    "        Generator_A_identity = gen_loss_weights[2] * identity_A\n",
    "        Generator_A_cam = gen_loss_weights[3] * cam_A\n",
    "\n",
    "\n",
    "        Generator_B_gan = gen_loss_weights[0] * G_ad_loss_B\n",
    "        Generator_B_cycle = gen_loss_weights[1] * reconstruction_A\n",
    "        Generator_B_identity = gen_loss_weights[2] * identity_B\n",
    "        Generator_B_cam = gen_loss_weights[3] * cam_B\n",
    "        \n",
    "        Generator_A_loss = Generator_A_gan + Generator_A_cycle + Generator_A_identity + Generator_A_cam\n",
    "        Generator_B_loss = Generator_B_gan + Generator_B_cycle + Generator_B_identity + Generator_B_cam\n",
    "        \n",
    "        Discriminator_A_loss = D_ad_loss_A + D_cam_loss_A\n",
    "        Discriminator_B_loss = D_ad_loss_B + D_cam_loss_B\n",
    "\n",
    "\n",
    "    generator_g_gradients = tape.gradient(Generator_A_loss, \n",
    "                                        gen_g.trainable_variables)\n",
    "    generator_f_gradients = tape.gradient(Generator_B_loss, \n",
    "                                        gen_f.trainable_variables)\n",
    "\n",
    "    discriminator_x_gradients = tape.gradient(Discriminator_A_loss, \n",
    "                                            dis_x.trainable_variables)\n",
    "    discriminator_y_gradients = tape.gradient(Discriminator_B_loss, \n",
    "                                            dis_y.trainable_variables)\n",
    "\n",
    "\n",
    "    gen_g_optimizer.apply_gradients(zip(generator_g_gradients, \n",
    "                                            gen_g.trainable_variables))\n",
    "\n",
    "    gen_f_optimizer.apply_gradients(zip(generator_f_gradients, \n",
    "                                            gen_f.trainable_variables))\n",
    "\n",
    "    dis_x_optimizer.apply_gradients(zip(discriminator_x_gradients,\n",
    "                                                dis_x.trainable_variables))\n",
    "\n",
    "    dis_y_optimizer.apply_gradients(zip(discriminator_y_gradients,\n",
    "                                                dis_y.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "gen_loss_weights = [1, 10, 100, 1000] ### lambda값조절하면서 돌리자!\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    n = 0\n",
    "    nn = 0\n",
    "    while True:\n",
    "        try:\n",
    "            image_x = X_array[n * batch_size:(n + 1) * batch_size] \n",
    "            image_y = Y_array[n * batch_size:(n + 1) * batch_size] \n",
    "        except:\n",
    "            image_x = X_array[n * batch_size:]\n",
    "            image_y = Y_array[n * batch_size:]\n",
    "        if len(image_x) == 0:\n",
    "            break\n",
    "        train_step(image_x, image_y, gen_loss_weights)\n",
    "        if n % 10 == 0:\n",
    "            print (nn, '/', end='')\n",
    "            nn += 1\n",
    "        n+=1\n",
    "        if len(image_x) < batch_size:\n",
    "            break\n",
    "\n",
    "    generate_images(gen_g, sample_x, epoch)\n",
    "    \n",
    "    gen_g.save('./model_save/gen_g.h5')\n",
    "    gen_f.save('./model_save/gen_f.h5')\n",
    "    dis_x.save('./model_save/dis_x.h5')\n",
    "    dis_y.save('./model_save/dis_y.h5')\n",
    "\n",
    "    print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
    "                                                      time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_img(model, test_input):\n",
    "    prediction,_ = model(test_input)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "\n",
    "    display_list = [test_input[0], prediction[0]]\n",
    "    title = ['Input Image', 'Predicted Image']\n",
    "\n",
    "    for i in range(2):\n",
    "        plt.subplot(1, 2, i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i])\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "sample_x = load_img('./data/selfie/female_10.jpg', target_size = (256, 256))\n",
    "sample_x = img_to_array(sample_x) / 255.\n",
    "sample_x = np.reshape(sample_x, (-1, 256, 256, 3))\n",
    "generate_img(gen_g, sample_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_img(model, test_input, epoch):\n",
    "    prediction,_ = model(test_input)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "\n",
    "    display_list = [test_input[0], prediction[0]]\n",
    "    title = ['Input Image', 'Predicted Image']\n",
    "\n",
    "    for i in range(2):\n",
    "        plt.subplot(1, 2, i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i])\n",
    "        plt.axis('off')\n",
    "    plt.savefig('./result/{:04d}.jpg'.format(epoch))\n",
    "\n",
    "for i, sample_x in enumerate(X_array):\n",
    "    sample_x = np.reshape(sample_x, (-1, 256, 256, 3))\n",
    "    generate_img(gen_g, sample_x, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
